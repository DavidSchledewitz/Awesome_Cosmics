{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALPIDE: Instructions to use the ALPIDE telescope and analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load standard libraries\n",
    "\n",
    "import numpy as np   # standard numerics library\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt   # for making plots\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Testing\n",
    "\n",
    "1) The first step is to get the right parameters at which we want to use the detector. Therefore two different tests are done: the threshold and the noise occupancy test. The test is executed for different internal (DACs like VCASN, ITHR) and external (Backbias voltage, referred to as BB or VBB) parameters (see more on google documentation).\n",
    "\n",
    "2) After the tests are done, the data has to be read out to find the information we want (THreshold and Noise at given set of parameters)\n",
    "\n",
    "3) Out of extensive research it was found that a threshold of around 100 electrons is optimal for the operation of ALPIDE. By plotting all values over their parameters, you find the dependence of the threshold from the parameters and you can determine the best sets of parameters for operation.\n",
    "\n",
    "\n",
    "Next the script for executing the threshold test is shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#---the first line is important to execute this file via linux terminal.\n",
    "#---If your system complains about a python version, use python3 (if this doesnt work, python2.7) instead of python\n",
    "\n",
    "# loading new packages packages\n",
    "import sys\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "#import the datasheet,where all test-configurations are given\n",
    "RN,BBV,VCASN,ITHR = np.loadtxt(\"Sheet.csv\",delimiter=\",\",usecols=(0,1,2,3),skiprows=1,unpack=True)\n",
    "###\"Sheet.csv\" is in the same directory as this script and contains information about the parameters you want to test.\n",
    "### RunNumber,BackBiasVoltage,VCASN,ITHR,,Threshold [DAC]\n",
    "### 1,0,47,40,,\n",
    "### 2,0,47,50,,\n",
    "### 3,0,47,60,,\n",
    "\n",
    "#Alternatively you can generate the arrays also in this script.\n",
    "\n",
    "VCASN2 = VCASN +12 #This is the correlation between VCASN and VCASN2 for every value\n",
    "\n",
    "#definition, which allows to replace the value of a key-parameter\n",
    "def replace_key(filename, key, value):\n",
    "    #read the file and make a copy where we will change the values\t\n",
    "    with open(filename, 'r') as f_in, tempfile.NamedTemporaryFile(\n",
    "            'w', dir=os.path.dirname(filename), delete=False) as f_out:\n",
    "\t#go through the lines of the original file\n",
    "        for line in f_in.readlines():\n",
    "\t    #look for the line where the key-parameter is placed\n",
    "            if line.startswith(key):\n",
    "\t\t#change the parameter, by splitting the line and replace the last part by the wished value\n",
    "                line = \" \".join((line.split(' ')[0],'{}'.format(value)))\n",
    "\t    # overwrite the line in the copy\n",
    "            f_out.write(line)\n",
    "                                  \n",
    "    # remove original file\n",
    "    os.unlink(filename)\n",
    " \n",
    "    # rename new file to the original\n",
    "    os.rename(f_out.name, filename)\n",
    "\n",
    "# execute the replacement for all parameters we want to change \n",
    "for i in range (len(RN)):\n",
    "    replace_key(\"Config.cfg\", \"ITHR \",str(int(ITHR[i]))+\"\\n\" )\n",
    "    replace_key(\"Config.cfg\", \"VCASN \",str(int(VCASN[i]))+\"\\n\" )\n",
    "    replace_key(\"Config.cfg\", \"VCASN2 \",str(int(VCASN2[i]))+\"\\n\" )\n",
    "    #run the test with args: THRESHHOLD MASKSTAGES DAC-start-value DAC-stop-value\n",
    "    # NOTE this is an older version of the config and test executing file. Newer versions might look differrent.\n",
    "    #      That means, you have to check, wether ./runtest is still the right command and Config.cfg looks still the same (especcially looking at the key)\n",
    "    #######subprocess.call([\"./runtest\", \"THRESHOLD\", \"164\", \"0\", \"50\"])\n",
    "    \n",
    "    # noise occup. test works similar, but with other command than runtest at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the config file looked like"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Config file\n",
    "# File format: each parameter setting is a single line.\n",
    "# The format of the lines is: <parameter name><TAB><parameter value>\n",
    "# Empty lines or lines starting with # are ignored\n",
    "# Config file does not need to be \"complete\", for parameters not given in the config file a default value is used.\n",
    "\n",
    "# Multi-chip devices (Module or Telescope): parameters for a single chip are denoted by _ChipNumber (e.g. VCASN_4)\n",
    "# Chip numbering goes from 0 to NCHIPS - 1\n",
    "# If suffix is missing (i.e. VCASN instead of VCASN_4), the given value is used for all chips\n",
    "\n",
    "# First line has to be DEVICE (Values: CHIP, TELESCOPE, MODULE)\n",
    "DEVICE CHIP\n",
    "\n",
    "# In case DEVICE is not CHIP, the second line has to be the number of chips NCHIPS\n",
    "#NCHIPS 1\n",
    "\n",
    "# ID of DUT, interpretation depends on DEVICE type:\n",
    "# CHIP: ignored\n",
    "# MODULE: chip whose ID = DUTID\n",
    "# TELESCOPE: chip connected to DAQ Board with jumpered address = DUTID\n",
    "# Default: 0\n",
    "#DUTID 16\n",
    "\n",
    "# Chip type, allowed values PALPIDE1 and PALPIDE2\n",
    "CHIP   PALPIDE4\n",
    "\n",
    "## DAQ board version (default: V3, other options: V1, V2)\n",
    "#\n",
    "# Setting is relevant from pALPIDE-3 firmware v247E0611 on\n",
    "#\n",
    "# How to recognise the versions:\n",
    "# V3: single lemo connectors only, label on the backside\n",
    "# V1/V2: double stack lemo connectors\n",
    "DAQBOARD V3\n",
    "\n",
    "\n",
    "# Measurement mode, allowed settings ANALOGUE, DIGITAL, SOURCE, NOISE\n",
    "# Defines which of the settings for STROBEBLENGTH, PULSEDELAY and PULSELENGTH are used\n",
    "\n",
    "# Chip Id: meaningful only for CHIP >= pALPIDE2, default = 0\n",
    "CHIPID\t   16\n",
    "\n",
    "MODE   ANALOGUE\n",
    "\n",
    "# DAC Values, format DAC name, followed by integer value;\n",
    "# allowed DAC names: VAUX, VRESET, VCASN, VCASP, VPULSEL, VPULSEH, IRESET, IAUX2, IBIAS, IDB, ITHR\n",
    "ITHR\t 60\n",
    "VCASN\t47\n",
    "VCASN2\t 59\n",
    "VCLIP\t 0\n",
    "#VRESETD 147\n",
    "#VCASP 80\n",
    "#IRESET 100\n",
    "#VRESET 180\n",
    "#VRESETD 30\n",
    "#VCLIP 255\n",
    "\n",
    "# pALPDIDEfs readout mode, allowed values A, B\n",
    "# default value: B\n",
    "\n",
    "#READOUTMODE\t A\n",
    "\n",
    "# Settings for pulse, strobe and readout timing\n",
    "\n",
    "# a) settings, which are used with one value for all type of measurements\n",
    "#    known parameters: STROBELENGTH, STROBEBDELAY, READOUTDELAY\n",
    "\n",
    "STROBELENGTH\t10\n",
    "#STROBELENGTH\t2 \n",
    "\n",
    "STROBEBDELAY\t50\n",
    "READOUTDELAY\t300\n",
    "\n",
    "# b) parameters, whose setting depends on the type of measurement (chosen by MODE)\n",
    "\n",
    "# b.1) STROBEBLENGTH for the different modes, recognised parameters:\n",
    "#        STROBEBLENGTHSTANDARD (used for analogue, noise and data taking (to be checked))\n",
    "#        STROBEBLENGTHDIGITAL  (used for digital injections)\n",
    "#        STROBEBLENGTHSOURCE   (used for source scans; long for random coincidences)\n",
    "STROBEBLENGTHSTANDARD\t400 \n",
    "\n",
    "#STROBEBLENGTHDIGITAL\t200\n",
    "STROBEBLENGTHDIGITAL\t2000\n",
    "STROBEBLENGTHSOURCE\t10000\n",
    "\n",
    "# b.2) PULSEDELAY for digital and analogue injections (PULSEDELAYDIGITAL, PULSEDELAYANALOGUE) (minimum value is 26!)\n",
    "#PULSEDELAYANALOGUE\t26\n",
    "PULSEDELAYANALOGUE\t40\n",
    "PULSEDELAYDIGITAL\t40\n",
    "\n",
    "\n",
    "\n",
    "# b.3) PULSELENGTH for digital and analogue injections\n",
    "#PULSELENGTHANALOGUE\t2000\n",
    "PULSELENGTHANALOGUE\t2000\n",
    "PULSELENGTHDIGITAL\t200\n",
    "\n",
    "\n",
    "# pALPIDE-2 specific settings\n",
    "\n",
    "# DDR: Double Data Rate on parallel port. Values = 1 (DDR enabled), 0 (default, DDR disabled)\n",
    "DDR     0\n",
    "\n",
    "# PORT: Data port, Values PARALLEL (default, board reads from parallel port), SERIAL (board reads from serial port)\n",
    "PORT\tPARALLEL\n",
    "\n",
    "INVERTCMU\t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to analyze the data acquired with the the threshold scan, an additional script can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d466a510bf4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mxaxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "graphical_output=False\n",
    "\n",
    "def scurve_fit(steps, ninj):\n",
    "    dvs=sorted(steps.keys())\n",
    "    m=0\n",
    "    s=0\n",
    "    den=0\n",
    "    for dv1,dv2 in zip(dvs[:-1],dvs[1:]):\n",
    "        ddv=dv2-dv1\n",
    "        mdv=0.5*(dv2+dv1)\n",
    "        n1=1.0*steps[dv1]/ninj\n",
    "        n2=1.0*steps[dv2]/ninj\n",
    "        dn=n2-n1\n",
    "        den+=dn/ddv\n",
    "        m+=mdv*dn/ddv\n",
    "        s+=mdv**2*dn/ddv\n",
    "    if den>0:\n",
    "        if s>m*m:\n",
    "            s=(s-m*m)**0.5\n",
    "        m/=den\n",
    "        s/=den\n",
    "    return m,s\n",
    "\n",
    "thresholds = []\n",
    "rmss = []\n",
    "\n",
    "xaxis=np.arange(50)\n",
    "with open(sys.argv[1]) as f:\n",
    "    pr = pc = -1\n",
    "    for line in f:\n",
    "        r,c,dv,hits = [int(i) for i in line.strip().split()]\n",
    "        if not (pr==r and pc==c):\n",
    "            if pr>=0 and pc>=0:\n",
    "                m,s=scurve_fit(steps,50)\n",
    "                thresholds.append(m)\n",
    "                rmss.append(s)\n",
    "            steps = {}\n",
    "        else:\n",
    "            steps[dv] = hits\n",
    "        pr=r\n",
    "        pc=c\n",
    "print(np.mean(thresholds))\n",
    "print(np.mean(rmss))\n",
    "\n",
    "if graphical_output:\n",
    "    plt.figure()\n",
    "    plt.xlabel('Threshold in DAC')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Whole ALPIDE')\n",
    "    plt.hist(thresholds,range=(0,30), bins=30)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('RMS in DAC')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Whole ALPIDE')\n",
    "    plt.hist(rmss,range=(0,1), bins=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be easily executed and written to a csv file with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-efd655f955d6>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-efd655f955d6>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    PATHTOFILES=$1\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#The goal with this script is to take in lots of Data files and automatically\n",
    "#extract Data from them, and write them into an output file\n",
    "#\n",
    "#This file needs to be in the same directory as thresh.py\n",
    "#You\"ll need to be able to run python scripts via shell (./script.py)\n",
    "#for that to work, you might need to change the first line of the python script\n",
    "#to #!/usr/bin/env pythonX.X (depending on your version)\n",
    "\n",
    "############################# USER INPUT SECTION ###############################\n",
    "\n",
    "#1st argument is path\n",
    "PATHTOFILES=$1\n",
    "if [[ \"$PATHTOFILES\" == \"\" ]] ; then\n",
    "    echo \"Error: Please specify the directory of the data files\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Counting files...\"\n",
    "fi\n",
    "\n",
    "#Count, how many files are to be analyzed\n",
    "N=$(ls -la $PATHTOFILES | grep -c -e '.dat')\n",
    "printf \"Found $N .dat files, proceed? [y/n]\\n\"\n",
    "read PROCEED\n",
    "if [[ \"$PROCEED\" == \"y\" ]] ; then\n",
    "    echo \"Creating csv file...\"\n",
    "elif [[ \"$PROCEED\" == \"n\" ]] ; then\n",
    "    echo \"Script Cancelled\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Input not understood. Script Cancelled\"\n",
    "    exit 1\n",
    "fi\n",
    "################################################################################\n",
    "\n",
    "\n",
    "#Create a csv file\n",
    "printf \"Timestamp,VCASN,ITHR,Threshold [DAC], Threshold_Error\\n\" >> output.csv\n",
    "\n",
    "#Start to loop over all N files\n",
    "for i in $(ls $PATHTOFILES | grep '.dat'); do\n",
    "    #define the files to be worked with by cutting out the Timestamp\n",
    "    TIMESTAMP=$(echo $i | tail -c 18 | head -c 13)\n",
    "    printf \"Timestamp: $TIMESTAMP \\n\"\n",
    "    CONFIG=\"ScanConfig_$TIMESTAMP.cfg\"\n",
    "    \n",
    "    #Then extract Parameters from config file (Later add VBB)\n",
    "    VCASN=$(cat $PATHTOFILES$CONFIG | grep 'VCASN' | awk -F ' ' '{print $2}' | head -1)\n",
    "    ITHR=$(cat $PATHTOFILES$CONFIG | grep 'ITHR' | awk -F ' ' '{print $2}')\n",
    "\n",
    "    #Then use python script to calculate Threshold for that run\n",
    "    printf \"Starting evaluation for run $TIMESTAMP with ITHR=$ITHR and VCASN=$VCASN \\n\"\n",
    "    TRSH=$(./thresh.py $PATHTOFILES$i | head -1)\n",
    "    TRSHERR=$(./thresh.py $PATHTOFILES$i | tail -1)\n",
    "    printf \"The calculated threshold in DAC values is $TRSH. Now writing to csv file...\\n\\n\"\n",
    "\n",
    "    # Write everything to the csv file\n",
    "    printf '%s\\n' \"$TIMESTAMP\" \"$VCASN\" \"$ITHR\" \"$TRSH\" \"$TRSHERR\" | paste -sd ',' >> output.csv\n",
    "done\n",
    "\n",
    "echo Succeeded!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noiseoccupancy\n",
    "\n",
    "For the Noise occupancy, the following script does the trick of getting Fake Hit Rate in an csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# loading packages\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import csv\n",
    "\n",
    "### we want to import the data files\n",
    "# Therefore seperately read the configs and the Noise_occ data and build collect the needed data\n",
    "# for every timestamp pair\n",
    "# import the files and get the information out of them \n",
    "\n",
    "# get the path to read the files (this was specific for my directory--->need to be changed, depending on your data location)\n",
    "data_path = os.path.join(os.path.split(os.path.split(os.path.dirname(__file__))[0])[0],\"some_directory\",\"telescope_data\",\"Data\",\"bb0_noise\")\n",
    "data_path_2 = os.path.join(os.path.split(os.path.split(os.path.dirname(__file__))[0])[0],\"some_directory\",\"telescope_data\",\"Data\",\"bb3_noise\")\n",
    "# create arrays for storing the information we want in the csv: VCASN, VCASN2, ITHR, #triggers from the cfg file\n",
    "# from the .dat files we need the number of hits\n",
    "VCASN = []\n",
    "VCASN2= []\n",
    "ITHR  = []\n",
    "NTRIG = []\n",
    "NHITS = []\n",
    "BB    = []\n",
    "\n",
    "\n",
    "###### defenition to get the value of a specific keyword from a file\n",
    "def get_value(filename, key):\n",
    "\n",
    "    # open file\n",
    "    file = open(filename, \"r\")\n",
    "\n",
    "    # read the lines\n",
    "    for line in file.readlines():\n",
    "\n",
    "        # find the line with the given keyword\n",
    "        if line.startswith(key):\n",
    "\n",
    "            # get the value corresponding to the keyword\n",
    "            value = line.split()[1]\n",
    "            return value\n",
    "\n",
    "\n",
    "\n",
    "####### def for calculating the Fakehitrate\n",
    "\n",
    "# creating a container for the fakehitrate (FHR)\n",
    "FHR = []\n",
    "# error of FHR\n",
    "d_FHR = []\n",
    "\n",
    "def fake_rate(hits, Ntrig):\n",
    "\n",
    "    # test if the array is 0-dimensional, if size = 1:  calculate without the len()\n",
    "    if (hits.size == 1):\n",
    "\n",
    "        #FHR, if only one event in this configuration\n",
    "        FHR.append(hits/(Ntrig*524288))\n",
    "\n",
    "        #corresponding error\n",
    "        d_FHR.append(np.sqrt(hits)/(Ntrig*524288))\n",
    "      \n",
    "    else:\n",
    "\n",
    "        #calculating the FakeHitRate for every configuration (assumption that one pixel would fire once)\n",
    "        FHR.append(sum(hits)/(Ntrig*524288))\n",
    "\n",
    "        #corresponding error\n",
    "        d_FHR.append(np.sqrt(sum(hits))/(Ntrig*524288))\n",
    "\n",
    "## calc by: number of hits in all tested(documented) pixels divided by \n",
    "## the number of tested pixles(all=524288) times the number of test loops (NTRIG)\n",
    "\n",
    "## error calculated by sqrt(hits)/(NTRIG*number of pixels) <- intrinsic noise in the production of e^-\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ MAIN CODE #####################################\n",
    "#######BB=0V\n",
    "\n",
    "### search in the noise_occ_folder for files\n",
    "# we need a container for the .dat files to test later , if there exists a .dat file to every .cfg file\n",
    "Dat = []\n",
    "\n",
    "for i in sorted(os.listdir(data_path)):\n",
    "\n",
    "    # Data for the #hits is stored in the .dat files beginning with \"NoiseOcc\"\n",
    "    if i.startswith(\"NoiseOcc\"):\n",
    "        path = os.path.join(data_path,i)\n",
    "\n",
    "        # since we dont need the adress of the pixel, we will only import the #hits\n",
    "        NHITS.append(np.loadtxt(path ,delimiter=\" \",usecols=(2), dtype= int))\n",
    "\n",
    "        ### extract the timestamp\n",
    "        # Therefore split the path to get the timestamp\n",
    "        file_type, date, time_ext = i.split(\"_\")   # in time_ext still the.cfg need to be cut off\n",
    "        time = time_ext.split(\".\")[0]\n",
    "\n",
    "        #create the timestamp with both time and Hit data\n",
    "        timestamp = date + \"_\" + time\n",
    "        \n",
    "        # contain the .dat files to compare them later on\n",
    "        Dat.append(timestamp)\n",
    "\n",
    "### now search for the config files and compare them to the .dat\n",
    "for i in sorted(os.listdir(data_path)):\n",
    "\n",
    "    # Config files start with \"ScanConfig\" -> search for them\n",
    "    if i.startswith(\"ScanConfig\"):\n",
    "        \n",
    "        #define the whole filepath\n",
    "        path = os.path.join(data_path,i)\n",
    "\n",
    "        # reading out the data we want and put them into the according arrays, created at the beginning\n",
    "        VCASN.append(int(get_value(path,\"VCASN\")))\n",
    "        VCASN2.append(int(get_value(path,\"VCASN2\")))\n",
    "        ITHR.append(int(get_value(path, \"ITHR\")))\n",
    "        BB.append(int(0))\n",
    "        \n",
    "        #we need the number of triggers also for the fakehit rate as varaible, so we define one here\n",
    "        num_triggers = int(100000)#get_value(path, \"NTRIGGERS\"))   ###no trigger in new config file\n",
    "        NTRIG.append(num_triggers)\n",
    "\n",
    "        ### test, if there is also a coresponding NoiseOcc file\n",
    "        # Therefore split the path to get the timestamp\n",
    "        file_type, date, time_ext = i.split(\"_\")   # in time_ext still the.cfg need to be cut off\n",
    "        time = time_ext.split(\".\")[0]\n",
    "\n",
    "        #create the timestamp:\n",
    "        timestamp = date + \"_\" + time\n",
    "        \n",
    "\n",
    "        ## testing if a corresponding noiseocc file excists:\n",
    "        # if yes: calculate the fakehitrate\n",
    "        if timestamp in Dat:\n",
    "\n",
    "            #use the index of the corresponding timestamp to find the right Hit data\n",
    "            Hit_data = NHITS[Dat.index(timestamp)]\n",
    "            fake_rate(Hit_data,num_triggers)\n",
    "        \n",
    "        #if no: assume the sensitvity limit = 1.907e-11\n",
    "        else:\n",
    "            #FHR_sensitivity limit\n",
    "            FHR.append(1/(num_triggers*524288))#\n",
    "\n",
    "            #d_FHR_sensitivity limit\n",
    "            d_FHR.append(1/(num_triggers*524288))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################BB=3V\n",
    "### here: do the same as above the the second data sample (data_path_2)\n",
    "\n",
    "###creating a csv file\n",
    "with open(\"FakeHitRate.csv\",\"w\", newline=\"\") as f:\n",
    "\n",
    "    ## writing the data we need: the configuration parameters and the Fakehitrate with error\n",
    "    #creating the the header\n",
    "    header = [\"BB\",\" VCASN\", \" VCASN2\", \" ITHR\", \" NTRIGGERS\", \" FHR\", \" Error_FHR\"]\n",
    "    writing = csv.DictWriter(f, fieldnames= header)\n",
    "\n",
    "    # write the header in the file\n",
    "    writing.writeheader()\n",
    "    \n",
    "    # put in the values\n",
    "    for j in range(len(VCASN)):\n",
    "        writing.writerow({\"BB\" : BB[j],\" VCASN\" : VCASN[j], \" VCASN2\" : VCASN2[j], \" ITHR\" : ITHR[j],\n",
    "         \" NTRIGGERS\" : NTRIG[j], \" FHR\" : FHR[j], \" Error_FHR\" : d_FHR[j]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
